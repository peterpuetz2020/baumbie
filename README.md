# ğŸŒ³ BaumBie

BaumBie bringt Menschen mit der Natur in Verbindung. Die interaktive Karte zeigt BÃ¤ume an und bringt sie zum Sprechen. FÃ¼r jeden Baum zeigt die App grundlegende Informationen an, etwa Alter, Baumart oder HÃ¶he. AuÃŸerdem ist der Wasserbedarf und die Regenmenge der letzten Zeit zu sehen. Vor allem kÃ¶nnen Nutzer:innen sich spielerisch in einem Chat mit dem Baum auseinandersetzen und ihm Fragen stellen. Eine weitere wichtige Funktion der App: Die BÃ¤ume kÃ¶nnen adoptiert werden. So erfahren Nutzer:innen live, wie es ihrem Baum geht und kÃ¶nnen beim GieÃŸen des Baums helfen. Ein Baum kann mehrere Pat:innen haben. Das soll auch Nachbarschaften zusammenbringen.

Grundlage der Karte ist aktuell das Baumkataster der Stadt Bielefeld, es sind also alle StadtbÃ¤ume zu sehen. Das Projekt ist so angelegt, dass auch Privatpersonen, oder andere Organisationen Daten mit uns teilen kÃ¶nnen, damit wir ihre BÃ¤ume in der App zeigen kÃ¶nnen.

Das Projekt ist inspiriert von "GieÃŸ den Kiez" aus Berlin. Es wird entwickelt von Ehrenamtlichen aus dem Verein Code for Bielefeld e.V. Wir sind ein gemeinnÃ¼tziger Verein fÃ¼r digitale Bildung, Open Source, Open Data und Civic Coding. Wir setzen unsere technischen und kreativen FÃ¤higkeiten ein, um unsere Stadt zu verbessern und sind Teil der bundesweiten Initiative "Code for Germany" von der Open Knowledge Foundation. Wir freuen uns Ã¼ber weitere Interessierte.

## ğŸ§± Tech Stack

Unsere Anwendung basiert auf einem kompakten Fullstack-Setup:

- **Frontend: Svelte**

  Svelte ist ein komponentenbasiertes JavaScript-Framework, Ã¤hnlich wie React oder Vue.js. Im Gegensatz zu diesen nutzt Svelte kein virtuelles DOM, sondern kompiliert Komponenten bereits beim Build in effizienten, direkt ausfÃ¼hrbaren JavaScript-Code. Das fÃ¼hrt zu geringeren Ladezeiten und erleichtert die Umsetzung interaktiver BenutzeroberflÃ¤chen - bei uns vollstÃ¤ndig in TypeScript umgesetzt.

- **Backend: Supabase**

  Supabase ist ein Open-Source-Backend-as-a-Service auf Basis von PostgreSQL. Wir kÃ¶nnen damit Authentifizierung, Datenbankzugriff, Datei-Uploads und Ã¶ffentliche APIs direkt aus der Datenbank heraus konfigurieren â€“ ohne zusÃ¤tzlichen Server-Code, was die KomplexitÃ¤t senkt.

- **Conversational AI: Voiceflow**

  Voiceflow ist eine Plattform zur Erstellung von Chatbots und Sprachassistenten Ã¼ber ein grafisches No-Code-Interface. Sie erlaubt es uns, die Chatdialoge mit einzelnen BÃ¤umen visuell zu modellieren, ohne selbst Code schreiben zu mÃ¼ssen. Die Kommunikation mit Voiceflow erfolgt Ã¼ber einen per Edge Function angebundenen API-Endpunkt in Supabase.

  > ğŸš¨ Da die Preisstruktur von Voiceflow derzeit unklar ist und die Plattform nicht selbst gehostet werden kann, evaluieren wir mittelfristig Alternativen â€“ z.B. durch eigene LLM-Backends.

## ğŸ” Umgebungsvariablen

Die Anwendung benÃ¶tigt eine `.env`-Datei im Projekt-Root, die dem Muster von [`.env.example`](./.env.example) folgt. Sie enthÃ¤lt die Zugangsdaten fÃ¼r Supabase und Voiceflow.

### ğŸ—„ï¸ Supabase

| Variable                    | Beschreibung                                                                                                        |
| --------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| `VITE_SUPABASE_URL`         | Supabase-Projekt-URL (Cloud-Instanz oder lokal), z.â€¯B. `https://xyzabc12.supabase.co` oder `http://localhost:54321` |
| `VITE_SUPABASE_ANON_KEY`    | Ã–ffentlicher SchlÃ¼ssel fÃ¼r clientseitige Authentifizierung und Lesezugriff auf die Datenbank                        |
| `SUPABASE_SERVICE_ROLE_KEY` | Geheimer Server-SchlÃ¼ssel mit Schreibrechten (âš ï¸ **Nicht im Frontend verwenden** âš ï¸)                                    |

`VITE_SUPABASE_URL` wird gemeinsam mit dem Ã¶ffentlichen `VITE_SUPABASE_ANON_KEY` in der zentralen [client.ts](./frontend/src/lib/supabase/client.ts) verwendet, um den Supabase-Client im Frontend zu initialisieren.

Der private `SUPABASE_SERVICE_ROLE_KEY` kommt vor allem in den Python-Skripten im Verzeichnis [`/preparation`](/preparation) zum Einsatz â€“ etwa beim Importieren von Baumdaten oder dem Anlegen von Tabellen. DarÃ¼ber hinaus wird er in Supabase Edge Functions genutzt, z.B. zum LÃ¶schen von Nutzerkonten Ã¼ber die Admin-API.

> ğŸš¨ FÃ¼r die Entwicklung empfiehlt es sich, zusÃ¤tzlich eine `.env.local` anzulegen, die auf die lokale Supabase-Instanz verweist. Falls vorhanden, Ã¼berschreibt sie standardmÃ¤ÃŸig die `.env`.

### ğŸ’¬ Voiceflow

| Variable            | Beschreibung                                                                                                                |
| ------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| `VOICEFLOW_API_KEY` | API-SchlÃ¼ssel fÃ¼r die Voiceflow-Integration (nur in der Supabase Edge Function [`chat`](/supabase/functions/chat/index.ts)) |

## ğŸ› ï¸ Lokales Dev-Setup

### ğŸ³ Supabase-Instanz starten

FÃ¼r die lokale Entwicklung muss eine Supabase-Instanz aufgesetzt werden. DafÃ¼r verwenden wir die [`supabase-cli`](https://supabase.com/docs/guides/cli).

Installiere sie zum Beispiel mit `npm` (du kannst alternativ auch andere Paketmanager nutzen):

```bash
npm install -g supabase-cli
```

Die Supabase CLI verwendet intern **Docker**, um Dienste wie PostgreSQL, Auth und Studio lokal bereitzustellen. Docker ist eine Container-Laufzeitumgebung: Die Supabase CLI startet mehrere Container (fÃ¼r Datenbank, Auth etc.) und kapselt sie voneinander ab â€“ Ã¤hnlich wie Mini-VMs, aber schneller und leichtgewichtiger.

Stelle also sicher, dass die Docker Engine auf deinem System installiert und aktiv ist:

- **macOS/Windows**: Installiere [Docker Desktop](https://www.docker.com/products/docker-desktop/), starte es und lasse es im Hintergrund laufen. Der kostenlose Personal-Plan ist ausreichend.
- **Linux**: Folge der [offiziellen Anleitung zur Docker-Installation](https://docs.docker.com/engine/install/) fÃ¼r deine Distribution.

Wenn Supabase CLI und Docker eingerichtet sind, kannst du deine lokale Instanz im **Projekt-Root** starten:

```bash
supabase start
```

Sobald die Instanz lÃ¤uft, kannst du das Supabase Studio â€“ die grafische OberflÃ¤che zur Verwaltung deiner lokalen Datenbank â€“ im Browser unter http://127.0.0.1:54323/ aufrufen.

> ğŸš¨ Beim ersten Start fÃ¼hrt die Supabase CLI automatisch alle `.sql`-Migrations aus dem Ordner [supabase/migrations/](/supabase/migrations/) aus. Dadurch wird die im Projekt definierte Datenbankstruktur aufgebaut â€“ also alle Tabellen, Views, Policies und weitere SQL-Objekte, die in den Migrationen enthalten sind. Die Tabellen bleiben aber zunÃ¤chst leer, da in unserem Projekt kein Seed-Skript definiert ist.

### ğŸ›ï¸ Umgebungsvariablen setzen

Kopiere die Datei `.env.example` und benenne sie um in `.env.local`:

```bash
cp .env.example .env.local
```

Sobald du `supabase start` ausgefÃ¼hrt hast, zeigt dir das Terminal eine Liste mit Konfigurationswerten an â€“ darunter die URL deiner lokalen Instanz sowie die API-SchlÃ¼ssel.

> ğŸš¨ Die API URL bleibt immer http://127.0.0.1:54321 (bzw. http://localhost:54321). Kopiere dir den `anon key` und den `service_role key` aus dem Terminal-Output und notiere sie fÃ¼r die Konfiguration!

Trage die folgenden drei Werte (ohne AnfÃ¼hrungszeichen!) in deine `.env.local`-Datei ein:

```ini
VITE_SUPABASE_URL=http://localhost:54321
VITE_SUPABASE_ANON_KEY=<anon key>
SUPABASE_SERVICE_ROLE_KEY=<service_role key>
```

### â¬†ï¸ Migrationen answenden

Wenn du neue Tabellen oder Ã„nderungen an deiner Datenbankstruktur vornimmst, solltest du dafÃ¼r Migrationen erstellen. Supabase speichert sie als `.sql`-Dateien im Ordner [supabase/migrations/](/supabase/migrations/).

Beim ersten Start mit `supabase start` werden alle Migrationen automatisch angewendet.

SpÃ¤tere Ã„nderungen (z.â€¯B. neue Tabellen, Spalten oder Policies) erfordern jedoch einen manuellen Schritt:

```bash
supabase migrations up
```

Dieser Befehl fÃ¼hrt **alle noch nicht angewendeten Migrationen** aus und aktualisiert deine lokale Datenbankstruktur entsprechend.

### ğŸŒ± Baumdaten importieren & segmentieren

Nachdem die Supabase-Instanz lÃ¤uft und alle Tabellen eingerichtet wurden, kÃ¶nnen die Baumdaten importiert und fÃ¼r die performante Kartendarstellung vorbereitet werden.

#### ğŸ Virtuelle Python-Umgebung vorbereiten

Wechsle zunÃ¤chst ins `preparation`-Verzeichnis und erstelle eine virtuelle Python-Umgebung:

```bash
cd preparation
python3 -m venv .venv
source .venv/bin/activate
```

Die virtuelle Umgebung stellt sicher, dass alle benÃ¶tigten Python-Pakete sauber und unabhÃ¤ngig vom restlichen System installiert werden kÃ¶nnen.

Installiere anschlieÃŸend alle benÃ¶tigten AbhÃ¤ngigkeiten:

```bash
pip install -r requirements.txt
```

#### ğŸ“¥ Baumdaten importieren

Lege deine GeoJSON-Datei am besten im Verzeichnis `preparation/input/` ab. FÃ¼hre dann das Importskript aus und gib dabei den Pfad zu deiner Datei an, z.B.:

```bash
python import.py input/trees.geojson
```

Das Skript verwendet automatisch die Umgebungsvariablen aus `.env.local` (falls vorhanden) oder `.env`, um sich mit Supabase zu verbinden.

> ğŸš¨ Nach diesem Schritt solltest du im Supabase Studio (http://127.0.0.1:54323/) sehen kÃ¶nnen, dass insbesondere die `trees`-Tabelle mit Baumdaten befÃ¼llt wurde.

#### ğŸŒ Geo-Splitting der Baumdaten

Da es in Bielefeld Ã¼ber 80.000 StadtbÃ¤ume gibt, wÃ¤re es technisch ineffizient, alle Baumdaten gleichzeitig in der Karte zu laden. Das wÃ¼rde zu langen Ladezeiten und hohem Speicherverbrauch fÃ¼hren â€“ vor allem auf mobilen GerÃ¤ten.

Stattdessen teilen wir die Koordinaten der importierten BÃ¤ume nach dem Upload in kleinere GeoJSON-Dateien auf, sogenannte Segmente. Jede dieser Dateien enthÃ¤lt nur die BÃ¤ume eines bestimmten geografischen Ausschnitts.

Das Frontend lÃ¤dt dann ausschlieÃŸlich die Segmente, die zum aktuell sichtbaren Kartenausschnitt gehÃ¶ren. Erst wenn ein einzelner Baum im Detail angezeigt wird, wird dessen vollstÃ¤ndiger Datensatz direkt aus Supabase abgerufen. Das ermÃ¶glicht flÃ¼ssiges Rendering â€“ selbst bei zehntausenden BÃ¤umen â€“ und spart dabei Ladezeit und Ressourcen.

FÃ¼hre dazu im `preparation/`-Ordner das folgende Skript aus:

```bash
python supa_splitter.py
```

Das Skript lÃ¤dt die Koordinaten direkt aus der Supabase-Tabelle `tree_coordinates`, teilt sie in ein 10Ã—10-Raster und erstellt pro Rasterzelle eine Datei unter `preparation/segments/`.

ZusÃ¤tzlich wird eine Datei `segments_index.json` erzeugt, die die Ãœbersicht Ã¼ber alle _Bounding Boxes_ enthÃ¤lt â€“ also die rechteckigen geografischen Begrenzungen der einzelnen Segmente. Damit kann das Frontend gezielt nur jene Dateien laden, deren Bereich gerade auf der Karte sichtbar ist.

Kopiere oder verschiebe anschlieÃŸend die neu erstellten Segmente aus `preparation/segments/` nach `frontend/static/segments`. Dazu kannst du den `segments/`-Ordner entweder manuell verschieben oder folgenden Befehl ausfÃ¼hren:

```bash
cp -r preparation/segments frontend/static
```

### â–¶ï¸ App starten

Wechsle in den `frontend/`-Ordner und installiere alle benÃ¶tigten AbhÃ¤ngigkeiten:

```bash
cd frontend
npm install
```

AnschlieÃŸend kannst du das mit Svelte entwickelte Frontend im Entwicklungsmodus starten:

```
npm run dev
```

> ğŸš¨ Das Projekt lÃ¤uft nun standardmÃ¤ÃŸig unter http://localhost:5173. Du solltest jetzt eine Karte mit BÃ¤umen sehen.

### ğŸ§¹ Lokale Supabase zurÃ¼cksetzen

Mit folgenden Befehl kannst du die lokale Instanz wieder beenden:

```bash
supabase stop
```

Dieser Befehl beendet nur die laufenden Container, setzt aber nicht den Datenbankinhalt zurÃ¼ck. Supabase speichert alle Daten in einem Docker Volume, das unabhÃ¤ngig vom Container-Lifecycle bestehen bleibt.

Wenn du alle Daten dauerhaft lÃ¶schen und die lokale Instanz vollstÃ¤ndig zurÃ¼cksetzen mÃ¶chtest, kannst du die zugehÃ¶rigen Volumes manuell entfernen:

1. Liste die lokalen Supabase-Volumes auf:

   ```bash
   docker volume ls
   ```

   Du solltest Volumes sehen, die dem Schema entsprechen:

   ```
   supabase_db_<Projektverzeichnis> \
   supabase_storage_<Projektverzeichnis> \
   supabase_config_<Projektverzeichnis> \
   supabase_edge_runtime_<Projektverzeichnis>
   ```

2. Entferne alle zugehÃ¶rigen Volumes:

   ```
   docker volume rm \
   supabase_db_<Projektverzeichnis> \
   supabase_storage_<Projektverzeichnis> \
   supabase_config_<Projektverzeichnis> \
   supabase_edge_runtime_<Projektverzeichnis>
   ```

   Dadurch wird die komplette lokale Supabase-Instanz gelÃ¶scht, inklusive Datenbank, Authentifizierung, Dateien und Konfiguration. Der Vorgang ist nicht umkehrbar.

## ğŸŒ Produktivbetrieb

Um BaumBie produktiv zu betreiben, verwendest du eine gehostete Supabase-Instanz in der Cloud.

### ğŸ§¾ Supabase-Projekt in der Cloud erstellen

Melde dich auf [https://app.supabase.com](https://app.supabase.com) an und erstelle ein neues Projekt. Folge den Anweisungen und wÃ¤hle als Region einen Ort, der mÃ¶glichst nah an deinen Nutzern liegt (z.â€¯B. Frankfurt fÃ¼r Deutschland).

### ğŸ”‘ Zugangsdaten abrufen

Nach der Erstellung deines Projekts erhÃ¤ltst du alle notwendigen Zugangsdaten im Supabase Studio:

1. Ã–ffne dein Projekt in [https://app.supabase.com](https://app.supabase.com)
2. Klicke unten links auf **Project Settings**
3. WÃ¤hle im Bereich **Configuration** den Punkt **Data API**
4. Dort findest du:
   - `Project URL` â†’ verwende diesen Wert als `VITE_SUPABASE_URL`
5. Klicke in diesem Bereich auf **"Go to API Keys"**, um zu den API-SchlÃ¼sseln zu gelangen:

   - `anon public` â†’ verwende als `VITE_SUPABASE_ANON_KEY`
   - `service_role secret` â†’ verwende als `SUPABASE_SERVICE_ROLE_KEY` **(nicht im Frontend verwenden!)**

   Lege eine `.env`-Datei im Projekt-Root an (z.â€¯B. durch Kopieren von `.env.example`) und trage die Werte ein:

```ini
VITE_SUPABASE_URL=<Project URL>
VITE_SUPABASE_ANON_KEY=<anon public>
SUPABASE_SERVICE_ROLE_KEY=<service_role secret>
```

### ğŸ› ï¸ Supabase CLI installieren & verbinden

Installiere die Supabase CLI (falls noch nicht geschehen):

```bash
npm install -g supabase-cli
```

Melde dich bei Supabase Ã¼ber die CLI an:

```bash
supabase login
```

AnschlieÃŸend verknÃ¼pfst du dein Projekt mit deiner Cloud-Instanz per Project ID, die du in oben deinen Project Settings findest oder aus der Project URL extrahieren kannst:

```bash
supabase link --project-ref <dein-project-ref>
```

### â¬†ï¸ Migrationen anwenden

Sobald dein Projekt verknÃ¼pft ist, kannst du alle vorhandenen Migrationen auf deine Cloud-Datenbank anwenden:

```bash
supabase db push
```

Dadurch werden alle Migrationsdateien angewendet, die lokal vorhanden, aber in der Supabase-Cloud noch nicht ausgefÃ¼hrt wurden â€“ also etwa Tabellen, Views, Policies und andere SQL-Objekte.

### ğŸŒ± Baumdaten importieren & segmentieren

Sobald deine Supabase-Cloud-Instanz eingerichtet und mit Migrationen befÃ¼llt ist, kannst du wie im lokalen Setup die Baumdaten importieren und segmentieren.

Folge dafÃ¼r dem beschriebenen Ablauf im Abschnitt **ğŸŒ± Baumdaten importieren & segmentieren** weiter oben.

Die dort beschriebenen Schritte zur Python-Umgebung, dem Import der GeoJSON-Datei sowie zur Segmentierung und Kopie ins Frontend bleiben unverÃ¤ndert â€“ wichtig ist lediglich, dass deine `.env`-Datei auf die Supabase-**Cloud-Instanz** zeigt.

### ğŸ›°ï¸ Frontend bauen & deployen

Erzeuge ein Produktions-Build deiner Svelte-App:

```bash
cd frontend
npm install
npm run build
```

Das erzeugte statische Frontend liegt unter `frontend/build/`. Du kannst es Ã¼ber beliebige Hoster (z.â€¯B. Zugriff.eu, Vercel, Netlify oder eigenes Hosting) ausliefern.
